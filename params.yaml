Decision Tree:
  criterion: ["gini", "entropy", "log_loss"]

Random Forest:
  n_estimators: [8, 16, 32, 128, 256]

Gradient Boosting:
  learning_rate: [0.1, 0.01, 0.05, 0.001]
  subsample: [0.6, 0.7, 0.75, 0.85, 0.9]
  n_estimators: [8, 16, 32, 64, 128, 256]

Logistic Regression: []

AdaBoost:
  learning_rate: [0.1, 0.01, 0.001]
  n_estimators: [8, 16, 32, 64, 128, 256]
